# ğŸ“¦ Projeto de ETL e AnÃ¡lise de TransaÃ§Ãµes Financeiras

## ğŸ“Œ DescriÃ§Ã£o
Este projeto tem como objetivo realizar um processo de **ETL (Extract, Transform, Load)** e anÃ¡lise de um dataset de transaÃ§Ãµes financeiras utilizando **Databricks** e **PySpark**. O foco principal Ã© extrair, limpar e transformar os dados para, posteriormente, calcular o gasto total por cliente e identificar os 3 clientes com maiores gastos.

## ConteÃºdo do Projeto

- ğŸ“‚ **Dataset:**  
  Um arquivo CSV contendo 100 linhas e 6 colunas, com os seguintes campos:
  - `transaction_id`: ID da transaÃ§Ã£o.
  - `date`: Data da transaÃ§Ã£o.
  - `customer_id`: ID do cliente.
  - `amount`: Valor da transaÃ§Ã£o.
  - `category`: Categoria da transaÃ§Ã£o (ex.: AlimentaÃ§Ã£o, Transporte, Lazer, EducaÃ§Ã£o, SaÃºde).
  - `payment_method`: MÃ©todo de pagamento (ex.: CartÃ£o de CrÃ©dito, CartÃ£o de DÃ©bito, Dinheiro, Pix).

- ğŸš€ **Problema Proposto:**  
  1. Carregar e tratar o dataset utilizando PySpark.
  2. Realizar a limpeza dos dados (verificaÃ§Ã£o de formataÃ§Ã£o, valores nulos, duplicatas).
  3. Calcular o total gasto por cada cliente e formatar o resultado com 2 casas decimais.
  4. Identificar os 3 clientes com maior gasto.
  
## Tecnologias Utilizadas

- **Databricks:** Plataforma para anÃ¡lise de dados e execuÃ§Ã£o de notebooks.
- **PySpark:** Framework para processamento distribuÃ­do de dados.
- **Pandas:** Utilizado inicialmente para a criaÃ§Ã£o do dataset.

## ğŸ“ˆ ConclusÃ£o

Este projeto demonstra a aplicaÃ§Ã£o de tÃ©cnicas de ETL e anÃ¡lise de dados utilizando Databricks e PySpark, desde a ingestÃ£o e validaÃ§Ã£o dos dados atÃ© a execuÃ§Ã£o de anÃ¡lises financeiras. 
